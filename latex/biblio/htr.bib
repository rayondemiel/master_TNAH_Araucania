
@article{alkhalafOCRBasedElectronicDocumentation2014,
  title = {{{OCR-Based Electronic Documentation Management System}}},
  author = {Alkhalaf, Khalaf},
  date = {2014},
  journaltitle = {International Journal of Innovation, Management and Technology},
  shortjournal = {IJIMT},
  volume = {5},
  number = {6},
  issn = {20100248},
  doi = {10.7763/IJIMT.2014.V5.560},
  url = {http://www.ijimt.org/index.php?m=content&c=index&a=show&catid=63&id=866},
  urldate = {2022-08-24},
  abstract = {Optical character recognition (OCR) is one of the latest technologies adopted in a lot of areas such as management, business, criminal and social networks. It consists of recognizing image-based characters and transforming them to real digital character that can be editing, written and displayed. In this paper we will demonstrate our experience on utilizing OCR technology to recognize some key information in selected management documents in Arabic language. In addition, this paper will discover the literature about OCR, address some challenges and share some important lessons with suggested research ideas that can be conducted in the feature.},
  langid = {english},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\AQAMYTGY\\Alkhalaf - 2014 - OCR-Based Electronic Documentation Management Syst.pdf}
}

@unpublished{anvariSurveyDeepLearning2022,
  title = {A {{Survey}} on {{Deep}} Learning Based {{Document Image Enhancement}}},
  author = {Anvari, Zahra and Athitsos, Vassilis},
  date = {2022-01-03},
  eprint = {2112.02719},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/2112.02719},
  urldate = {2022-05-11},
  abstract = {Digitized documents such as scientific articles, tax forms, invoices, contract papers, historic texts are widely used nowadays. These document images could be degraded or damaged due to various reasons including poor lighting conditions, shadow, distortions like noise and blur, aging, ink stain, bleed-through, watermark, stamp, etc. Document image enhancement plays a crucial role as a pre-processing step in many automated document analysis and recognition tasks such as character recognition. With recent advances in deep learning, many methods are proposed to enhance the quality of these document images. In this paper, we review deep learning-based methods, datasets, and metrics for six main document image enhancement tasks, including binarization, debluring, denoising, defading, watermark removal, and shadow removal. We summarize the recent works for each task and discuss their features, challenges, and limitations. We introduce multiple document image enhancement tasks that have received little to no attention, including over and under exposure correction, super resolution, and bleed-through removal. We identify several promising research directions and opportunities for future research.},
  archiveprefix = {arXiv},
  version = {4},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,htr}
}

@inproceedings{aradillasBoostingHandwritingText2018,
  title = {Boosting {{Handwriting Text Recognition}} in {{Small Databases}} with {{Transfer Learning}}},
  booktitle = {2018 16th {{International Conference}} on {{Frontiers}} in {{Handwriting Recognition}} ({{ICFHR}})},
  author = {Aradillas, José Carlos and Murillo-Fuentes, Juan José and Olmos, Pablo M.},
  date = {2018-08},
  eprint = {1804.01527},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  pages = {429--434},
  doi = {10.1109/ICFHR-2018.2018.00081},
  url = {http://arxiv.org/abs/1804.01527},
  urldate = {2022-08-27},
  abstract = {In this paper we deal with the offline handwriting text recognition (HTR) problem with reduced training datasets. Recent HTR solutions based on artificial neural networks exhibit remarkable solutions in referenced databases. These deep learning neural networks are composed of both convolutional (CNN) and long short-term memory recurrent units (LSTM). In addition, connectionist temporal classification (CTC) is the key to avoid segmentation at character level, greatly facilitating the labeling task. One of the main drawbacks of the CNNLSTM-CTC (CLC) solutions is that they need a considerable part of the text to be transcribed for every type of calligraphy, typically in the order of a few thousands of lines. Furthermore, in some scenarios the text to transcribe is not that long, e.g. in the Washington database. The CLC typically overfits for this reduced number of training samples. Our proposal is based on the transfer learning (TL) from the parameters learned with a bigger database. We first investigate, for a reduced and fixed number of training samples, 350 lines, how the learning from a large database, the IAM, can be transferred to the learning of the CLC of a reduced database, Washington. We focus on which layers of the network could be not re-trained. We conclude that the best solution is to re-train the whole CLC parameters initialized to the values obtained after the training of the CLC from the larger database. We also investigate results when the training size is further reduced. The differences in the CER are more remarkable when training with just 350 lines, a CER of 3.3\% is achieved with TL while we have a CER of 18.2\% when training from scratch. As a byproduct, the learning times are quite reduced. Similar good results are obtained from the Parzival database when trained with this reduced number of lines and this new approach.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,htr,Statistics - Machine Learning},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\W7RPYS93\\Aradillas et al. - 2018 - Boosting Handwriting Text Recognition in Small Dat.pdf;C\:\\Users\\cohum\\Zotero\\storage\\SDC4KR6A\\1804.html}
}

@inproceedings{campsReconnaissanceOptiqueCaracteres2021,
  title = {Reconnaissance optique des caractères  et des écritures manuscrites - Projet E-NDP},
  booktitle = {Séminaire Notre-Dame de Paris et son cloître},
  author = {Camps, Jean-Baptiste and Perreaux, Nicolas},
  date = {2021-02-16},
  location = {{Paris, France}},
  url = {https://outils.lamop.fr/lamop/mp3/E-Ndp/JBC-NP_e-NDP_OCR-et-HTR.pdf},
  langid = {french},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\TSYRQW6V\\Camps et Perreaux - Reconnaissance optique des caractères  et des écri.pdf}
}

@report{caronFormatsDonneesPour2021,
  title = {Formats de données pour la préservation à long terme : la politique de la BnF},
  author = {Caron, Bertrand and Cavalié, Etienne},
  date = {2021-04},
  number = {1},
  institution = {{Bibliothèque nationale de France}},
  location = {{Paris, France}},
  url = {https://www.bnf.fr/sites/default/files/2021-04/politiqueFormatsDePreservationBNF_20210408.pdf},
  langid = {french},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\EXCPPR9Q\\Caron - Formats de données pour la préservation à long ter.pdf}
}

@misc{chagueAccessibleTransparentPipeline2021,
  title = {An Accessible and Transparent Pipeline for Publishing Historical Egodocuments},
  author = {Chagué, Alix and Chiffoleau, Floriane},
  date = {2021-03},
  url = {https://hal.archives-ouvertes.fr/hal-03180669},
  urldate = {2022-08-19},
  abstract = {The automatization of the processing of documents oriented towards online publication and exploration by the humanities increases the rapidity of treatments like the transcription, but they should also be an opportunity to make the experimentation and the resulting corpora sustainable and reusable. The DAHN project (Dispositif de soutien à l’Archivistique et aux Humanités Numériques) relies on a joint interdisciplinary collaboration between Inria, the EHESS and the University of Le Mans. By taking the example of egodocuments, the project aims to create a ready-to-use digital and scientific publishing pipeline going from the material archive to an online publication. In this presentation, we introduce our method and guidelines for the processing of non-digital-native textual documents using open-source and easily hackable tools that guarantee visibility across an accessible pipeline, thus challenging the notions of a black box or scattered tools which tend to be hard to maintain in the long run.},
  keywords = {Digital editions,Egodocument,FAIR principles,htr,Optical Character Recognition,TEI encoding,Workflow},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\SG25USED\\Chagué et Chiffoleau - 2021 - An accessible and transparent pipeline for publish.pdf}
}

@inproceedings{chagueConditionsMutualisationPrincipes2022,
  title = {Conditions de La Mutualisation : Les Principes {{FAIR}} et {{HTR-United}}},
  shorttitle = {Conditions de La Mutualisation},
  booktitle = {Humanistica 2022},
  author = {Chagué, Alix},
  date = {2022-05},
  location = {{Montréal, Canada}},
  url = {https://hal.inria.fr/hal-03685731},
  urldate = {2022-09-13},
  keywords = {Données d'entraînement,FAIR principles,Handwritten text recognition,htr,Open science,Principes FAIR,Science ouverte,Training data,Transcription automatique de manuscrit},
  annotation = {Published: Humanistica 2022},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\D9Z8A8LY\\Chagué - 2022 - Conditions de la mutualisation  les principes FAI.pdf}
}

@software{chagueHTRUnitedManuMcFrench2022,
  title = {{{HTR-United}} - {{Manu McFrench V1}} ({{Manuscripts}} of {{Modern}} and {{Contemporaneous French}})},
  author = {Chagué, Alix and Clérice, Thibault},
  date = {2022-06-17},
  url = {https://zenodo.org/record/6657809},
  urldate = {2022-08-27},
  abstract = {Data were used from all French evenly mixed repository in HTR-United where images and transcription were readily available. Only the data from the 1600 to 2100 were used. 100 pages of Spanish Letters (19th) and a little of English are included (20th). All data follow the same transcription guidelines as far as we know. Superscript is presented with a \^ before the characters. eg. Mme abbreviation is written M\^me in all the dataset we used. Sometime, `{$<>$}` would be used to mark strike-through. All data were produced in eScriptorium with segmentation from Kraken.},
  organization = {{Zenodo}},
  version = {1.0.0},
  keywords = {htr,kraken_pytorch},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\8L6WCW48\\6657809.html}
}

@inproceedings{chagueHTRUnitedMutualisonsVerite2021,
  title = {{{HTR-United}} : {{Mutualisons}} La Vérité de Terrain !},
  shorttitle = {{{HTR-United}}},
  booktitle = {{{DHNord2021}} - {{Publier}}, Partager, Réutiliser Les Données de La Recherche : Les Data Papers et Leurs Enjeux},
  author = {Chagué, Alix and Clérice, Thibault and Romary, Laurent},
  date = {2021-11},
  publisher = {{MESHS}},
  location = {{Lille, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03398740},
  urldate = {2022-08-17},
  keywords = {Contrôle qualité,Datasets,Ground truth data,Handwritten Text Recognition,htr,Jeu de données,Quality Evaluation,Reconnaissance automatique d'écriture manuscrite,Vérité de terrain},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\R5RCY6JK\\Chagué et al. - 2021 - HTR-United  Mutualisons la vérité de terrain !.pdf}
}

@inproceedings{chaguePresentationProjetLectaurep2021,
  title = {Présentation Du Projet {{Lectaurep}} ({{Lecture}} Automatique de Répertoires)},
  booktitle = {Atelier Sur La Transcription Des Écritures Manuscrites - {{BnF DataLab}}},
  author = {Chagué, Alix and Rostaing, Aurélia},
  date = {2021-01},
  location = {{Paris, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03122019},
  urldate = {2022-08-19},
  keywords = {eScriptorium,Gestion de projet,htr,Infrastructure,Répertoires de notaire,Retour d'expérience,Set de données},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\PCVNCI2V\\Chagué et Rostaing - 2021 - Présentation du projet Lectaurep (Lecture automati.pdf}
}

@online{chiffoleauHowProduceModel,
  type = {Billet},
  title = {How to Produce a Model for the Segmentation},
  author = {Chiffoleau, Floriane},
  url = {https://digitalintellectuals.hypotheses.org/3844},
  urldate = {2022-08-19},
  abstract = {In order to facilitate the work on the automatic transcription of d’Estournelles’ correspondence, we identified the need~to develop a specific~segmentation model, in addition to a~transcription model. This post will talk about many elements already mentioned in this article so some specific parts will not be developed because it has already...},
  langid = {american},
  organization = {{Digital Intellectuals}},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\CX9SENW4\\3844.html}
}

@misc{chiffoleauProjetDAHNPipeline2022,
  title = {Le Projet {{DAHN}} : Une Pipeline Pour l'édition Numérique de Documents d'archives},
  shorttitle = {Le Projet {{DAHN}}},
  author = {Chiffoleau, Floriane and Baillot, Anne},
  date = {2022-04},
  url = {https://hal.archives-ouvertes.fr/hal-03628094},
  urldate = {2022-08-19},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\CTPC8XWA\\Chiffoleau et Baillot - 2022 - Le projet DAHN  une pipeline pour l'édition numér.pdf}
}

@software{clericeCREMMAANTestamentDePoilus2022,
  title = {{{CREMMA-AN-TestamentDePoilus}}},
  author = {Clérice, Thibault and Chagué, Alix},
  date = {2022},
  url = {https://github.com/HTR-United/CREMMA-AN-TestamentDePoilus},
  keywords = {htr}
}

@software{clericeHTRUnitedHTRVXHTRVX2022,
  title = {{{HTR-United}}/{{HTRVX}}: {{HTRVX}} : {{HTR Validation}} with {{XSD}}},
  author = {Clérice, Thibault and Chagué, Alix and Jacsont, Pauline},
  date = {2022-03},
  location = {{Paris, France}},
  url = {https://github.com/HTR-United/HTRVX},
  urldate = {2022-04-18},
  organization = {{HTR-United}},
  version = {0.0.10},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\32FWAT6U\\HTRVX.html}
}

@misc{clericeYouActuallyLook2022,
  title = {You {{Actually Look Twice At}} It ({{YALTAi}}): Using an Object Detection Approach Instead of Region Segmentation within the {{Kraken}} Engine},
  author = {Clérice, Thibault},
  date = {2022-07},
  abstract = {Layout Analysis (the identification of zones and their classification) is the first step along line segmentation in Optical Character Recognition and similar tasks. The ability of identifying main body of text from marginal text or running titles makes the difference between extracting the work full text of a digitized book and noisy outputs. We show that most segmenters focus on pixel classification and that polygonization of this output has not been used as a target for the latest competition on historical document (ICDAR 2017 and onwards), despite being the focus in the early 2010s. We propose to shift, for efficiency, the task from a pixel classification-based polygonization to an object detection using isothetic rectangles. We compare the output of Kraken and YOLOv5 in terms of segmentation and show that the later severely outperforms the first on small datasets (1110 samples and below). We release two datasets for training and evaluation on historical documents as well as a new package, YALTAi, which injects YOLOv5 in the segmentation pipeline of Kraken 4.1.},
  langid = {english},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\C8DU7YNR\\Clérice - You Actually Look Twice At it (YALTAi) using an o.pdf}
}

@inproceedings{desousanetoHTRFlorDeepLearning2020,
  title = {{{HTR-Flor}}: {{A Deep Learning System}} for {{Offline Handwritten Text Recognition}}},
  shorttitle = {{{HTR-Flor}}},
  booktitle = {2020 33rd {{SIBGRAPI Conference}} on {{Graphics}}, {{Patterns}} and {{Images}} ({{SIBGRAPI}})},
  author = {de Sousa Neto, Arthur Flor and Bezerra, Byron Leite Dantas and Toselli, Alejandro Hector and Lima, Estanislau Baptista},
  options = {useprefix=true},
  date = {2020-11},
  pages = {54--61},
  publisher = {{IEEE}},
  location = {{Recife/Porto de Galinhas, Brazil}},
  doi = {10.1109/SIBGRAPI51738.2020.00016},
  url = {https://ieeexplore.ieee.org/document/9266005/},
  urldate = {2022-08-19},
  abstract = {In recent years, Handwritten Text Recognition (HTR) has captured a lot of attention among the researchers of the computer vision community. Current state-of-the-art approaches for offline HTR are based on Convolutional Recurrent Neural Networks (CRNNs) excel at scene text recognition. Unfortunately, deep models such as CRNNs, Recurrent Neural Networks (RNNs) are likely to suffer from vanishing/exploding gradient problems when processing long text images, which are commonly found in scanned documents. Besides, they usually have millions of parameters which require huge amount of data, and computational resource. Recently, a new class of neural network architecture, called Gated Convolutional Neural Networks (Gated-CNN), has demonstrated potentials to complement CRNN methods in modeling. Therefore, in this paper, we present a new architecture for HTR, based on Gated-CNN, with fewer parameters and fewer layers, which is able to outperform the current state-of-the-art architectures for HTR. The experiment validates that the proposed model has statistically significant recognition results, surpassing previous HTR systems by an average of 33\% over five important handwritten benchmark datasets. Moreover, the proposed model is able to achieve satisfactory recognition rates even in case of few training data. Finally, its compact architecture requires less computational resources, which can be applied for real-world applications that have hardware limitations, such as robots and smartphones.},
  eventtitle = {2020 33rd {{SIBGRAPI Conference}} on {{Graphics}}, {{Patterns}} and {{Images}} ({{SIBGRAPI}})},
  isbn = {978-1-72819-274-1},
  langid = {english},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\GIF2DVDG\\de Sousa Neto et al. - 2020 - HTR-Flor A Deep Learning System for Offline Handw.pdf}
}

@software{durandNotairesParisRepertoires2021,
  title = {Notaires de {{Paris}} - {{Répertoires}}, Ground Truth for Various {{Parisian}} Registries of Notary Deeds ({{French}} 19th and 20th Centuries)},
  author = {Durand, Marc and Rostaing, Aurélia and Chagué, Alix},
  date = {2021},
  url = {https://github.com/HTR-United/lectaurep-repertoires},
  urldate = {2022-08-23},
  organization = {{HTR-United}},
  keywords = {Ground truth,htr,HTR},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\RMKAHJE6\\share.html}
}

@inproceedings{elagouniCombiningMultiScaleCharacter2012,
  title = {Combining {{Multi-Scale Character Recognition}} and {{Linguistic Knowledge}} for {{Natural Scene Text OCR}}},
  booktitle = {10th {{IAPR International Workshop}} on {{Document Analysis Systems}}, {{DAS}}},
  author = {Elagouni, Khaoula and Garcia, Christophe and Mamalet, Franck and Sébillot, Pascale},
  date = {2012-03},
  pages = {120--124},
  location = {{Gold Coast, Queensland, Australia}},
  url = {https://hal.archives-ouvertes.fr/hal-00753908},
  urldate = {2022-08-24},
  abstract = {Understanding text captured in real-world scenes is a challenging problem in the field of visual pattern recognition and continues to generate a significant interest in the OCR (Optical Character Recognition) community. This paper proposes a novel method to recognize scene texts avoiding the conventional character segmentation step. The idea is to scan the text image with multi-scale windows and apply a robust recognition model, relying on a neural classification approach, to every window in order to recognize valid characters and identify non valid ones. Recognition results are represented as a graph model in order to determine the best sequence of characters. Some linguistic knowledge is also incorporated to remove errors due to recognition confusions. The designed method is evaluated on the ICDAR 2003 database of scene text images and outperforms state-of-the-art approaches.},
  keywords = {convolutional neural networks,htr,language model,multi-scale character recognition,scene text recognition},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\YB7JZJZ6\\Elagouni et al. - 2012 - Combining Multi-Scale Character Recognition and Li.pdf}
}

@article{espana-boqueraSpanishDatasetReproducible2022,
  title = {A {{Spanish}} Dataset for Reproducible Benchmarked Offline Handwriting Recognition},
  author = {España-Boquera, Salvador and Castro-Bleda, María José},
  date = {2022-09-01},
  journaltitle = {Language Resources and Evaluation},
  shortjournal = {Language Resources and Evaluation},
  volume = {56},
  pages = {1--14},
  doi = {10.1007/s10579-022-09587-3},
  abstract = {In this paper, a public dataset for Offline Handwriting Recognition, along with an appropriate evaluation method to provide benchmark indicators at sentence level, is presented. This dataset, called SPA-Sentences, consists of offline handwritten Spanish sentences extracted from 1617 forms produced by the same number of writers. A total of 13,691 sentences comprising around 100,000 word instances out of a vocabulary of 3288 words occur in the collection. Careful attention has been paid to make the baseline experiments both reproducible and competitive. To this end, experiments are based on state-of-the-art recognition techniques combining convolutional blocks with one-dimensional Bidirectional Long Short Term Memory (LSTM) networks using Connectionist Temporal Classification (CTC) decoding. The scripts with the entire experimental setting have been made available. The SPA-Sentences dataset and its baseline evaluation are freely available for research purposes via the institutional University repository. We expect the research community to include this corpus, as is usually done with English IAM and French RIMES datasets, in their battery of experiments when reporting novel handwriting recognition techniques.},
  keywords = {htr}
}

@article{granellTranscriptionSpanishHistorical2018,
  title = {Transcription of {{Spanish Historical Handwritten Documents}} with {{Deep Neural Networks}}},
  author = {Granell, Emilio and Chammas, Edgard and Likforman-Sulem, Laurence and Martínez-Hinarejos, Carlos-D. and Mokbel, Chafic and Cîrstea, Bogdan-Ionuţ},
  date = {2018-01},
  journaltitle = {Journal of Imaging},
  volume = {4},
  number = {1},
  pages = {15},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2313-433X},
  doi = {10.3390/jimaging4010015},
  url = {https://www.mdpi.com/2313-433X/4/1/15},
  urldate = {2022-08-21},
  abstract = {The digitization of historical handwritten document images is important for the preservation of cultural heritage. Moreover, the transcription of text images obtained from digitization is necessary to provide efficient information access to the content of these documents. Handwritten Text Recognition (HTR) has become an important research topic in the areas of image and computational language processing that allows us to obtain transcriptions from text images. State-of-the-art HTR systems are, however, far from perfect. One difficulty is that they have to cope with image noise and handwriting variability. Another difficulty is the presence of a large amount of Out-Of-Vocabulary (OOV) words in ancient historical texts. A solution to this problem is to use external lexical resources, but such resources might be scarce or unavailable given the nature and the age of such documents. This work proposes a solution to avoid this limitation. It consists of associating a powerful optical recognition system that will cope with image noise and variability, with a language model based on sub-lexical units that will model OOV words. Such a language modeling approach reduces the size of the lexicon while increasing the lexicon coverage. Experiments are first conducted on the publicly available Rodrigo dataset, which contains the digitization of an ancient Spanish manuscript, with a recognizer based on Hidden Markov Models (HMMs). They show that sub-lexical units outperform word units in terms of Word Error Rate (WER), Character Error Rate (CER) and OOV word accuracy rate. This approach is then applied to deep net classifiers, namely Bi-directional Long-Short Term Memory (BLSTMs) and Convolutional Recurrent Neural Nets (CRNNs). Results show that CRNNs outperform HMMs and BLSTMs, reaching the lowest WER and CER for this image dataset and significantly improving OOV recognition.},
  issue = {1},
  langid = {english},
  keywords = {character-level language model,historical handwritten transcription,htr,out-of-vocabulary word recognition,word structure retrieval},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\FPFKKY45\\Granell et al. - 2018 - Transcription of Spanish Historical Handwritten Do.pdf;C\:\\Users\\cohum\\Zotero\\storage\\TJ93FUMJ\\htm.html}
}

@inproceedings{granetTransferLearningHandwriting2018,
  title = {Transfer {{Learning}} for {{Handwriting Recognition}} on {{Historical Documents}}},
  booktitle = {7th {{International Conference}} on {{Pattern Recognition Applications}} and {{Methods}} ({{ICPRAM}})},
  author = {Granet, Adeline and Morin, Emmanuel and Mouchère, Harold and Quiniou, Solen and Viard-Gaudin, Christian},
  date = {2018-01},
  location = {{Madeira, Portugal}},
  url = {https://hal.archives-ouvertes.fr/hal-01681126},
  urldate = {2022-08-27},
  abstract = {In this work, we investigate handwriting recognition on new historical handwritten documents using transfer learning. Establishing a manual ground-truth of a new collection of handwritten documents is time consuming but needed to train and to test recognition systems. We want to implement a recognition system without performing this annotation step. Our research deals with transfer learning from heterogeneous datasets with a ground-truth and sharing common properties with a new dataset that has no ground-truth. The main difficulties of transfer learning lie in changes in the writing style, the vocabulary, and the named entities over centuries and datasets. In our experiment, we show how a CNN-BLSTM-CTC neural network behaves, for the task of transcribing handwritten titles of plays of the Italian Comedy, when trained on combinations of various datasets such as RIMES, Georges Washington, and Los Esposalles. We show that the choice of the training datasets and the merging methods are determinant to the results of the transfer learning task.},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\4C9EKY7I\\Granet et al. - 2018 - Transfer Learning for Handwriting Recognition on H.pdf}
}

@inproceedings{gravesOfflineHandwritingRecognition2008,
  title = {Offline {{Handwriting Recognition}} with {{Multidimensional Recurrent Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Graves, Alex and Schmidhuber, Jürgen},
  date = {2008},
  volume = {21},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2008/hash/66368270ffd51418ec58bd793f2d9b1b-Abstract.html},
  urldate = {2022-08-25},
  abstract = {Offline handwriting recognition---the transcription of images of handwritten text---is an interesting task, in that it combines computer vision with sequence learning. In most systems the two elements are handled separately, with sophisticated preprocessing techniques used to extract the image features and sequential models such as HMMs used to provide the transcriptions. By combining two recent innovations in neural networks---multidimensional recurrent neural networks and connectionist temporal classification---this paper introduces a globally trained offline handwriting recogniser that takes raw pixel data as input. Unlike competing systems, it does not require any alphabet specific preprocessing, and can therefore be used unchanged for any language. Evidence of its generality and power is provided by data from a recent international Arabic recognition competition, where it outperformed all entries (91.4\% accuracy compared to 87.2\% for the competition winner) despite the fact that neither author understands a word of Arabic.},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\L39PYK8E\\Graves et Schmidhuber - 2008 - Offline Handwriting Recognition with Multidimensio.pdf}
}

@article{groverEvaluationOCRAccuracy,
  title = {An {{Evaluation}} of {{OCR Accuracy}}},
  author = {Grover, O. and Nartker, Thomas A. and Rice, Stephen V. and Kanai, Junichi and Nartker, Thomas A.},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\CKLWYT5S\\Grover et al. - An Evaluation of OCR Accuracy.pdf;C\:\\Users\\cohum\\Zotero\\storage\\PHVSVZ4L\\download.html}
}

@article{guptaOCRBinarizationImage2007,
  title = {{{OCR}} Binarization and Image Pre-Processing for Searching Historical Documents},
  author = {Gupta, Maya R. and Jacobson, Nathaniel P. and Garcia, Eric K.},
  date = {2007-02},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {40},
  number = {2},
  pages = {389--397},
  issn = {00313203},
  doi = {10.1016/j.patcog.2006.04.043},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320306002202},
  urldate = {2022-08-24},
  abstract = {We consider the problem of document binarization as a pre-processing step for optical character recognition (OCR) for the purpose of keyword search of historical printed documents. A number of promising techniques from the literature for binarization, pre-filtering, and post-binarization denoising were implemented along with newly developed methods for binarization: an error diffusion binarization, a multiresolutional version of Otsu’s binarization, and denoising by despeckling. The OCR in the ABBYY FineReader 7.1 SDK is used as a black box metric to compare methods. Results for 12 pages from six newspapers of differing quality show that performance varies widely by image, but that the classic Otsu method and Otsu-based methods perform best on average.},
  langid = {english},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\IBI8N9GW\\Gupta et al. - 2007 - OCR binarization and image pre-processing for sear.pdf}
}

@misc{kassAttentionHTRHandwrittenText2022,
  title = {{{AttentionHTR}}: {{Handwritten Text Recognition Based}} on {{Attention Encoder-Decoder Networks}}},
  shorttitle = {{{AttentionHTR}}},
  author = {Kass, Dmitrijs and Vats, Ekta},
  date = {2022-04-01},
  number = {arXiv:2201.09390},
  eprint = {2201.09390},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2201.09390},
  urldate = {2022-09-06},
  abstract = {This work proposes an attention-based sequence-to-sequence model for handwritten word recognition and explores transfer learning for data-efficient training of HTR systems. To overcome training data scarcity, this work leverages models pre-trained on scene text images as a starting point towards tailoring the handwriting recognition models. ResNet feature extraction and bidirectional LSTM-based sequence modeling stages together form an encoder. The prediction stage consists of a decoder and a content-based attention mechanism. The effectiveness of the proposed end-to-end HTR system has been empirically evaluated on a novel multi-writer dataset Imgur5K and the IAM dataset. The experimental results evaluate the performance of the HTR framework, further supported by an in-depth analysis of the error cases. Source code and pre-trained models are available at https://github.com/dmitrijsk/AttentionHTR.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\RRXSEIAV\\Kass et Vats - 2022 - AttentionHTR Handwritten Text Recognition Based o.pdf;C\:\\Users\\cohum\\Zotero\\storage\\5E6YBDTP\\2201.html}
}

@misc{kiesslingBADAMPublicDataset2019,
  title = {{{BADAM}}: {{A Public Dataset}} for {{Baseline Detection}} in {{Arabic-script Manuscripts}}},
  shorttitle = {{{BADAM}}},
  author = {Kiessling, Benjamin and Stökl Ben Ezra, Daniel and Miller, Matthew Thomas},
  date = {2019-07},
  url = {https://hal.archives-ouvertes.fr/hal-02167164},
  urldate = {2022-08-19},
  abstract = {The application of handwritten text recognition to historical works is highly dependant on accurate text line retrieval. A number of systems utilizing a robust baseline detection paradigm have emerged recently but the advancement of layout analysis methods for challenging scripts is held back by the lack of well-established datasets including works in non-Latin scripts. We present a dataset of 400 annotated document images from different domains and time periods. A short elaboration on the particular challenges posed by handwriting in Arabic script for layout analysis and subsequent processing steps is given. Lastly, we propose a method based on a fully convolutional encoder-decoder network to extract arbitrarily shaped text line images from manuscripts.},
  keywords = {Arabic,dataset,historical documents,htr,manuscripts},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\T3BIWVY2\\Kiessling et al. - 2019 - BADAM A Public Dataset for Baseline Detection in .pdf}
}

@inproceedings{kiesslingEScriptaNewDigital2019,
  title = {{{eScripta}}: {{A New Digital Platform}} for the {{Study}} of {{Historical Texts}} and {{Writing}}},
  shorttitle = {{{eScripta}}},
  booktitle = {Digital {{Humanities}} 2019},
  author = {Kiessling, Benjamin and Tissot, Robin and Stökl Ben Ezra, Daniel and Stokes, Peter Anthony},
  date = {2019-07},
  location = {{Utrecht , Pays-Bas}},
  url = {https://hal-ephe.archives-ouvertes.fr/hal-02310781},
  urldate = {2022-08-19},
  keywords = {htr},
  annotation = {Published: Digital Humanities 2019},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\RSUF3U2K\\Kiessling et al. - 2019 - eScripta A New Digital Platform for the Study of .pdf}
}

@inproceedings{kiesslingEScriptoriumOpenSource2019,
  title = {{{eScriptorium}}: {{An Open Source Platform}} for {{Historical Document Analysis}}},
  shorttitle = {{{eScriptorium}}},
  booktitle = {2019 {{International Conference}} on {{Document Analysis}} and {{Recognition Workshops}} ({{ICDARW}})},
  author = {Kiessling, Benjamin and Tissot, Robin and Stokes, Peter and Stökl Ben Ezra, Daniel},
  date = {2019-09},
  volume = {2},
  pages = {19--19},
  doi = {10.1109/ICDARW.2019.10032},
  abstract = {We describe the new open source document analysis and annotation platform eScriptorium. It allows to upload document collections, transcribe and segment them manually or automatically with the help of the kraken OCR engine.},
  eventtitle = {2019 {{International Conference}} on {{Document Analysis}} and {{Recognition Workshops}} ({{ICDARW}})},
  keywords = {document-analysis,GUI,handwritten-text-recognition,historical-documents,htr,Image segmentation,Layout,layout-segmentation,Manuals,Metadata,Training,Writing},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\Q3L3QS6P\\8893029.html}
}

@software{kiesslingKrakenOCRSystem2022,
  title = {The {{Kraken OCR}} System},
  author = {Kiessling, Benjamin},
  date = {2022-04},
  origdate = {2015-05-19T09:24:38Z},
  url = {https://kraken.re},
  urldate = {2022-08-27},
  abstract = {OCR engine for all the languages},
  version = {4.1.2},
  keywords = {htr}
}

@inproceedings{kiesslingKrakenUniversalText2019a,
  title = {Kraken - a Universal Text Recognizer for the Humanities},
  author = {Kiessling, Benjamin},
  date = {0008/2019-07-12},
  publisher = {{DataverseNL}},
  location = {{Utrecht , Pays-Bas}},
  doi = {10.34894/Z9G2EX},
  url = {https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/Z9G2EX},
  urldate = {2022-08-21},
  abstract = {Abstract of paper 0673 presented at the Digital Humanities Conference 2019 (DH2019), Utrecht , the Netherlands 9-12 July, 2019.},
  eventtitle = {Digital Humanities Conference 2019 (DH2019},
  langid = {french},
  keywords = {Arts and Humanities,htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\3E6RFGYI\\dataset.html}
}

@article{memonHandwrittenOpticalCharacter2020,
  title = {Handwritten {{Optical Character Recognition}} ({{OCR}}): {{A Comprehensive Systematic Literature Review}} ({{SLR}})},
  shorttitle = {Handwritten {{Optical Character Recognition}} ({{OCR}})},
  author = {Memon, Jamshed and Sami, Maira and Khan, Rizwan Ahmed and Uddin, Mueen},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {142642--142668},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3012542},
  abstract = {Given the ubiquity of handwritten documents in human transactions, Optical Character Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science that enables to translate various types of documents or images into analyzable, editable and searchable data. During last decade, researchers have used artificial intelligence/machine learning tools to automatically analyze handwritten and printed documents in order to convert them into electronic format. The objective of this review paper is to summarize research that has been conducted on character recognition of handwritten documents and to provide research directions. In this Systematic Literature Review (SLR) we collected, synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics) which were published between year 2000 to 2019. We followed widely used electronic databases by following pre-defined review protocol. Articles were searched using keywords, forward reference searching and backward reference searching in order to search all the articles related to the topic. After carefully following study selection process 176 articles were selected for this SLR. This review article serves the purpose of presenting state of the art results and techniques on OCR and also provide research directions by highlighting research gaps.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Bibliographies,Character recognition,classification,Databases,deep learning,feature extraction,htr,languages,Optical character recognition,Optical character recognition software,Optical imaging,Protocols,Systematics},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\9JSHTRMD\\Memon et al. - 2020 - Handwritten Optical Character Recognition (OCR) A.pdf;C\:\\Users\\cohum\\Zotero\\storage\\G35ATTD7\\9151144.html}
}

@inproceedings{mouffletAnsExperimentationTechnologie2021,
  title = {5 ans d’expérimentation de la technologie HTR aux Archives nationales},
  booktitle = {Futurs Fantastiques},
  author = {Moufflet, Jean-François},
  date = {2021},
  pages = {39},
  publisher = {{BNF}},
  location = {{Paris, France}},
  url = {https://www.bnf.fr/sites/default/files/2022-01/futurs_fantastiques_moufflet.pdf},
  langid = {french},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\YR22HGGD\\Moufflet - 2021 - 5 ans d’expérimentation de la technologie HTR aux .pdf}
}

@online{n.c.ExperimentationsLECTAUREP,
  title = {Expérimentations – LECTAUREP},
  author = {N.C.},
  url = {https://lectaurep.hypotheses.org/category/experimentations},
  urldate = {2022-08-20},
  langid = {french},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\IFKF9H7C\\experimentations.html}
}

@report{noemieOCRHTRGraphie2022,
  title = {OCR / HTR et graphie arabe},
  shorttitle = {OCR / HTR et graphie arabe},
  author = {{Noëmie} and {Lucas} and Fur, Doria Le},
  date = {2022-04},
  series = {Cahier du GIS},
  number = {3},
  institution = {{GIS Moyen-Orient et Mondes musulmans}},
  url = {http://majlis-remomm.fr/72481},
  urldate = {2022-08-19},
  langid = {french},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\S7FPNG2J\\72481.html}
}

@inproceedings{pincheCREMMALabProjectHandwritten2022,
  title = {{{CREMMALab Project}}: {{Handwritten}} Text Recognition ({{HTR}}) for Medieval Manuscripts},
  shorttitle = {{{CREMMALab Project}}},
  booktitle = {Digital {{Humanities}} 2022},
  author = {Pinche, Ariane},
  date = {2022-07},
  location = {{Tokyo, Japan}},
  url = {https://hal.archives-ouvertes.fr/hal-03719504},
  urldate = {2022-08-21},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\RJBHIITJ\\Pinche - 2022 - CREMMALab Project Handwritten text recognition (H.pdf}
}

@misc{pincheHTRModelsGenericity2022,
  title = {{{HTR Models}} and Genericity for {{Medieval Manuscripts}}},
  author = {Pinche, Ariane},
  date = {2022-07},
  url = {https://hal.archives-ouvertes.fr/hal-03736532},
  urldate = {2022-08-21},
  abstract = {Within the infrastructure of the CREMMA project (Consortium for Handwriting Recognition of Ancient Materials) supported by the DIM (research funded by the Île-de-France Region) MAP (Ancient and Heritage Materials), the CREMMALab 1 project combines research questions, creation and release of data from medieval French literary manuscripts for HTR. The objective of the CREMMALab project is to propose open training data and HTR models for medieval documents. All data and models produced by the project are already available in the CREMMA Medieval repository (Pinche 2022) on HTR-united catalogue (Chagué, Clérice, and Chiffoleau, 2021). In accordance with this objective, the project implements transcription protocols to optimise the training of HTR models and to produce homogeneous and shareable data and models.},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\FSTNALD2\\Pinche - 2022 - HTR Models and genericity for Medieval Manuscripts.pdf}
}

@inproceedings{puigcerverAreMultidimensionalRecurrent2017,
  title = {Are {{Multidimensional Recurrent Layers Really Necessary}} for {{Handwritten Text Recognition}}?},
  booktitle = {2017 14th {{IAPR International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}})},
  author = {Puigcerver, Joan},
  date = {2017-11},
  volume = {01},
  pages = {67--72},
  location = {{Kyoto, Japon}},
  issn = {2379-2140},
  doi = {10.1109/ICDAR.2017.20},
  url = {http://www.elvoldelhomeocell.net/pubs/jpuigcerver_icdar2017.pdf},
  abstract = {Current state-of-the-art approaches to offline Handwritten Text Recognition extensively rely on Multidimensional Long Short-Term Memory networks. However, these architectures come with quite an expensive computational cost, and we observe that they extract features visually similar to those of convolutional layers, which are computationally cheaper. This suggests that the two-dimensional long-term dependencies, which are potentially modeled by multidimensional recurrent layers, may not be essential to achieve a good recognition accuracy, at least in the lower layers of the architecture. In this work, an alternative model is explored that relies only on convolutional and one-dimensional recurrent layers that achieves better or equivalent results than those of the current state-of-the-art architecture, and runs significantly faster. In addition, we observe that using random distortions during training as synthetic data augmentation dramatically improves the accuracy of our model. Thus, are multidimensional recurrent layers really necessary for Handwritten Text Recognition? Probably not.},
  keywords = {Computational modeling,Computer architecture,convolutional neural networks,Error analysis,Feature extraction,handwritten text recognition,Hidden Markov models,htr,long short-term memory,recurrent neural networks,statistical hypothesis testing,Text recognition,Training},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\L6MUY2B2\\authors.html}
}

@article{sanchezSetBenchmarksHandwritten2019,
  title = {A Set of Benchmarks for {{Handwritten Text Recognition}} on Historical Documents},
  author = {Sánchez, Joan Andreu and Romero, Verónica and Toselli, Alejandro H. and Villegas, Mauricio and Vidal, Enrique},
  date = {2019-10},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {94},
  pages = {122--134},
  issn = {00313203},
  doi = {10.1016/j.patcog.2019.05.025},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320319302006},
  urldate = {2022-08-21},
  abstract = {Handwritten Text Recognition is a important requirement in order to make visible the contents of the myriads of historical documents residing in public and private archives and libraries world wide. Automatic Handwritten Text Recognition (HTR) is a challenging problem that requires a careful combination of several advanced Pattern Recognition techniques, including but not limited to Image Processing, Document Image Analysis, Feature Extraction, Neural Network approaches and Language Modeling. The progress of this kind of systems is strongly bound by the availability of adequate benchmarking datasets, software tools and reproducible results achieved using the corresponding tools and datasets. Based on English and German historical documents proposed in recent open competitions at ICDAR and ICFHR conferences between 2014 and 2017, this paper introduces four HTR benchmarks in order of increasing complexity from several points of view. For each benchmark, a specific system is proposed which overcomes results published so far under comparable conditions. Therefore, this paper establishes new state of the art baseline systems and results which aim at becoming new challenges that would hopefully drive further improvement of HTR technologies. Both the datasets and the software tools used to implement the baseline systems are made freely accessible for research purposes.},
  langid = {english},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\794HP4LB\\Sánchez et al. - 2019 - A set of benchmarks for Handwritten Text Recogniti.pdf}
}

@article{sousanetoRobustHandwrittenRecognition2022,
  title = {A Robust Handwritten Recognition System for Learning on Different Data Restriction Scenarios},
  author = {de Sousa Neto, Arthur Flor and Leite Dantas Bezerra, Byron and Hector Toselli, Alejandro and Baptista Lima, Estanislau},
  date = {2022-07-01},
  journaltitle = {Pattern Recognition Letters},
  shortjournal = {Pattern Recognition Letters},
  volume = {159},
  pages = {232--238},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2022.04.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865522001052},
  urldate = {2022-08-19},
  abstract = {Handwritten Text Recognition (HTR) systems have gained interest in fields of academic research and commercial applications. Deep learning techniques, and more precisely Convolutional Neural Networks (CNNs), have enabled many recent successes in the computer vision community. However, due to high computational costs, applying CNNs to many real applications is challenging since the specific training data is restricted in many cases. Therefore, in this paper, we present a Gated-CNN-BGRU optical model capable of dealing with this complex challenge. The proposed model was evaluated on five well-known datasets in HTR (Bentham, IAM, RIMES, Saint Gall, and Washington). Additionally, we redefine the training and validation partitions for each dataset, progressively varying the percentage of data between both partitions to create a total of 50 scenarios with different data volumes. The experiment validates and shows that the proposed model presents statistically significant results, surpassing the current models by an average of 2.96 and 8.91 percentage points in character and word recognition accuracy. In the most complex scenario of using 49 images for training, we achieved character and word precision of 87.25\% and 71.54\% respectively. That means an improvement of 78.32 and 53.54 percentage points, respectively, of the state-of-the-art optical models.},
  langid = {english},
  keywords = {Deep neural networks,Gated convolutional recurrent neural network,htr,Offline handwritten text recognition,Optical character recognition}
}

@online{stokesEScriptoriumOutilPour,
  type = {Billet},
  title = {eScriptorium : un outil pour la transcription automatique des documents},
  shorttitle = {eScriptorium},
  author = {Stokes, Peter A.},
  url = {https://ephenum.hypotheses.org/1412},
  urldate = {2022-08-22},
  abstract = {Le but de l’eScriptorium, dans sa finalité, est de concevoir un outil de production pour des éditions numériques et pour toute la chaîne nécessaire, dont la transcription représente ici la première brique. Nous bénéficions...},
  langid = {french},
  organization = {{EphéNum}},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\RG4EXTFG\\1412.html}
}

@article{stokesEScriptoriumVREManuscript,
  title = {The {{eScriptorium VRE}} for {{Manuscript Cultures}}},
  author = {Stokes, Peter A. and Kiessling, Benjamin and Stökl Ben Ezra, Daniel and Tissot, Robin and Gargem, El Hassene},
  journaltitle = {Classics@Journal},
  url = {https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-gargem/},
  urldate = {2022-08-02},
  abstract = {Classical scholarship that engages issues of great significance to a wide range of cultural and scholarly concerns},
  langid = {american},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\N3LJQINC\\classics18-stokes-kiessling-stokl-ben-ezra-tissot-gargem.html}
}

@article{stokesPalaeographyImageProcessingSolutions2007a,
  title = {Palaeography and {{Image-Processing}}: {{Some Solutions}} and {{Problems}}},
  shorttitle = {Palaeography and {{Image-Processing}}},
  author = {Stokes, Peter Anthony},
  date = {2007-03},
  journaltitle = {Digital Medievalist},
  volume = {3},
  publisher = {{University of Lethbridge}},
  doi = {10.16995/dm.15},
  url = {https://halshs.archives-ouvertes.fr/halshs-01728323},
  urldate = {2022-08-24},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\SZGJXMVR\\halshs-01728323.html}
}

@misc{strobelEvaluationHTRModels2022,
  title = {Evaluation of {{HTR}} Models without {{Ground Truth Material}}},
  author = {Ströbel, Phillip Benjamin and Clematide, Simon and Volk, Martin and Schwitter, Raphael and Hodel, Tobias and Schoch, David},
  date = {2022-04-29},
  number = {arXiv:2201.06170},
  eprint = {2201.06170},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2201.06170},
  urldate = {2022-08-29},
  abstract = {The evaluation of Handwritten Text Recognition (HTR) models during their development is straightforward: because HTR is a supervised problem, the usual data split into training, validation, and test data sets allows the evaluation of models in terms of accuracy or error rates. However, the evaluation process becomes tricky as soon as we switch from development to application. A compilation of a new (and forcibly smaller) ground truth (GT) from a sample of the data that we want to apply the model on and the subsequent evaluation of models thereon only provides hints about the quality of the recognised text, as do confidence scores (if available) the models return. Moreover, if we have several models at hand, we face a model selection problem since we want to obtain the best possible result during the application phase. This calls for GT-free metrics to select the best model, which is why we (re-)introduce and compare different metrics, from simple, lexicon-based to more elaborate ones using standard language models and masked language models (MLM). We show that MLM-based evaluation can compete with lexicon-based methods, with the advantage that large and multilingual transformers are readily available, thus making compiling lexical resources for other metrics superfluous.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\TUQXWWD3\\Ströbel et al. - 2022 - Evaluation of HTR models without Ground Truth Mate.pdf;C\:\\Users\\cohum\\Zotero\\storage\\VD7D8UUZ\\2201.html}
}

@inproceedings{strobelHowMuchData2020,
  title = {How {{Much Data Do You Need}}? {{About}} the {{Creation}} of a {{Ground Truth}} for {{Black Letter}} and the {{Effectiveness}} of {{Neural OCR}}},
  shorttitle = {How {{Much Data Do You Need}}?},
  booktitle = {Proceedings of the 12th {{Language Resources}} and {{Evaluation Conference}}},
  author = {Ströbel, Phillip Benjamin and Clematide, Simon and Volk, Martin},
  date = {2020-05},
  pages = {3551--3559},
  publisher = {{European Language Resources Association}},
  location = {{Marseille, France}},
  url = {https://aclanthology.org/2020.lrec-1.436},
  urldate = {2022-08-21},
  abstract = {Recent advances in Optical Character Recognition (OCR) and Handwritten Text Recognition (HTR) have led to more accurate textrecognition of historical documents. The Digital Humanities heavily profit from these developments, but they still struggle whenchoosing from the plethora of OCR systems available on the one hand and when defining workflows for their projects on the other hand.In this work, we present our approach to build a ground truth for a historical German-language newspaper published in black letter. Wealso report how we used it to systematically evaluate the performance of different OCR engines. Additionally, we used this ground truthto make an informed estimate as to how much data is necessary to achieve high-quality OCR results. The outcomes of our experimentsshow that HTR architectures can successfully recognise black letter text and that a ground truth size of 50 newspaper pages suffices toachieve good OCR accuracy. Moreover, our models perform equally well on data they have not seen during training, which means thatadditional manual correction for diverging data is superfluous.},
  eventtitle = {{{LREC}} 2020},
  isbn = {979-10-95546-34-4},
  langid = {english},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\N3JZH5G6\\Ströbel et al. - 2020 - How Much Data Do You Need About the Creation of a.pdf}
}

@software{terrielKaMIlib2022,
  title = {{{KaMI-lib}}},
  author = {Terriel, Lucas and Chagué, Alix},
  date = {2022-08-08T15:38:01Z},
  doi = {10.5281/zenodo.1234},
  url = {https://github.com/KaMI-tools-project/KaMi-lib},
  urldate = {2022-08-28},
  abstract = {HTR / OCR models evaluation agnostic Python package, originally based on the Kraken transcription system.},
  version = {0.1.3},
  keywords = {htr}
}

@thesis{terrielRepresenterEvaluerDonnees2020,
  type = {mémoire de master « Technologies numériques appliquées à l’histoire », dir. Alix Chagué et Thibault Clérice},
  title = {Représenter et Évaluer Les Données Issues Du Traitement Automatique d’un Corpus de Documents Historiques. {{L}}’exemple de La Reconnaissance Des Écritures Manuscrites Dans Les Répertoires de Notaires Du Projet {{LectAuRep}}.},
  author = {Terriel, Lucas},
  date = {2020},
  institution = {{École nationale des chartes}},
  location = {{Paris}},
  url = {https://github.com/Lucaterre/L-TERRIEL_memoireDeStage_M2TNAH_ENC},
  editora = {Chagué (dir.), Alix and Clérice (dir.), Thibault},
  editoratype = {collaborator},
  keywords = {htr}
}

@misc{tomoiagaFieldTypingImproved2019,
  title = {Field Typing for Improved Recognition on Heterogeneous Handwritten Forms},
  author = {Tomoiaga, Ciprian and Feng, Paul and Salzmann, Mathieu and Jayet, Patrick},
  date = {2019-09-22},
  number = {arXiv:1909.10120},
  eprint = {1909.10120},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1909.10120},
  urldate = {2022-08-28},
  abstract = {Offline handwriting recognition has undergone continuous progress over the past decades. However, existing methods are typically benchmarked on free-form text datasets that are biased towards good-quality images and handwriting styles, and homogeneous content. In this paper, we show that state-of-the-art algorithms, employing long short-term memory (LSTM) layers, do not readily generalize to real-world structured documents, such as forms, due to their highly heterogeneous and out-of-vocabulary content, and to the inherent ambiguities of this content. To address this, we propose to leverage the content type within an LSTM-based architecture. Furthermore, we introduce a procedure to generate synthetic data to train this architecture without requiring expensive manual annotations. We demonstrate the effectiveness of our approach at transcribing text on a challenging, real-world dataset of European Accident Statements.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\S4EV7ZMB\\Tomoiaga et al. - 2019 - Field typing for improved recognition on heterogen.pdf;C\:\\Users\\cohum\\Zotero\\storage\\4TUQIWH3\\1909.html}
}

@inproceedings{torresHTRFineTuning2022,
  title = {{{HTR}} Fine‑tuning for Medieval Manuscripts Models: Strategies and Evaluation},
  author = {Torres, Sergio and Jolivet, Vincent},
  date = {2022-06-23/2022-06-24},
  publisher = {{Ecole nationale des chartes}},
  url = {https://dahtr.sciencesconf.org/},
  urldate = {2022-08-21},
  eventtitle = {Documents Anciens et Reconnaissance Automatique Des Écritures Manuscrites},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\TRHF82G8\\dahtr.sciencesconf.org.html}
}

@article{xamenaEndtoendPlatformEvaluation2021,
  title = {End-to-End Platform Evaluation for {{Spanish Handwritten Text Recognition}}},
  author = {Xamena, Eduardo and Barboza, Héctor Emanuel and Orozco, Carlos Ismael},
  date = {2021-12-20},
  journaltitle = {Ciencia y Tecnología},
  shortjournal = {CyT},
  pages = {81--95},
  issn = {2344-9217, 1850-0870},
  doi = {10.18682/cyt.vi21.4327},
  url = {https://dspace.palermo.edu/ojs/index.php/cyt/article/view/4327},
  urldate = {2022-08-21},
  abstract = {The task of automated recognition of handwritten texts requires various phases and technologies both optical and language related. This article describes an approach for performing this task in a comprehensive manner, using machine learning throughout all phases of the process. In addition to the explanation of the employed methodology, it describes the process of building and evaluating a model of manuscript recognition for the Spanish language. The original contribution of this article is given by the training and evaluation of Offline HTR models for Spanish language manuscripts, as well as the evaluation of a platform to perform this task in a complete way. In addition, it details the work being carried out to achieve improvements in the models obtained, and to develop new models for different complex corpora that are more difficult for the HTR task.},
  langid = {english},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\G2AMDUTH\\Xamena et al. - 2021 - End-to-end platform evaluation for Spanish Handwri.pdf}
}

@article{xamenaEvaluacionPlataformaCompleta2021,
  title = {Evaluación de una plataforma completa para Reconocimiento de Textos Manuscritos en Español},
  author = {Xamena, Eduardo and Barbosa, Héctor and Orozco, Carlos Ismael},
  date = {2021},
  journaltitle = {Ciencia y tecnología},
  number = {21},
  pages = {6},
  publisher = {{Universidad de Palermo (UP)}},
  issn = {1850-0870, 2344-9217},
  url = {https://dialnet.unirioja.es/servlet/articulo?codigo=8148856},
  urldate = {2022-08-21},
  abstract = {Autorías: Eduardo Xamena, Héctor Barbosa, Carlos Ismael Orozco. Localización: Ciencia y tecnología. Nº. 21, 2021. Artículo de Revista en Dialnet.},
  langid = {spanish},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\N9WCXD6G\\Xamena et al. - 2021 - Evaluación de una plataforma completa para Reconoc.pdf;C\:\\Users\\cohum\\Zotero\\storage\\3Z6LQ8PZ\\articulo.html}
}

@article{zarriQuelquesAspectsTechniques1977,
  title = {Quelques aspects techniques de l'exploitation informatique des documents textuels : saisie des données et problèmes de sortie},
  shorttitle = {Quelques aspects techniques de l'exploitation informatique des documents textuels},
  author = {Zarri, Gian Piero},
  date = {1977},
  journaltitle = {Publications de l'École Française de Rome},
  volume = {31},
  number = {1},
  pages = {399--413},
  publisher = {{Persée - Portail des revues scientifiques en SHS}},
  url = {https://www.persee.fr/doc/efr_0000-0000_1977_act_31_1_2286},
  urldate = {2022-08-24},
  langid = {fre},
  keywords = {htr},
  file = {C\:\\Users\\cohum\\Zotero\\storage\\DYMTU4Q7\\efr_0000-0000_1977_act_31_1_2286.html}
}


